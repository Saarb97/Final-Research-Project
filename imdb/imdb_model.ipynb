{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:35:07.866264Z",
     "start_time": "2025-03-23T14:35:05.479346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from https://www.kaggle.com/code/suvroo/complete-nlp-pipeline#RoPE-(Robust-Positional-Embeddings)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb0ff8048fd6bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:35:08.036073Z",
     "start_time": "2025-03-23T14:35:07.867263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3902ab383d2552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:35:08.183929Z",
     "start_time": "2025-03-23T14:35:08.037071Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187868f7-2737-42bb-aff3-73870302c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/saarbu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b343760d5e31fd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:35:26.006023Z",
     "start_time": "2025-03-23T14:35:08.184929Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text\n",
    "df['review'] = df['review'].apply(remove_tags)\n",
    "df_post_tags = df.copy()\n",
    "\n",
    "sw_list = stopwords.words('english')\n",
    "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5388ca9a004113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:09.601289Z",
     "start_time": "2025-03-17T15:03:09.598665Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782ca0671b297358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:09.610288Z",
     "start_time": "2025-03-17T15:03:09.603287Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# # Define the model name\n",
    "# model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Load the base model\n",
    "# base_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# # Check if a GPU is available and set the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Define a custom model with a new classification head\n",
    "# class BinarySentimentModel(nn.Module):\n",
    "#     def __init__(self, base_model, num_labels=2):\n",
    "#         super(BinarySentimentModel, self).__init__()\n",
    "#         self.base_model = base_model\n",
    "#         hidden_size = base_model.config.hidden_size\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask=None, **kwargs):\n",
    "#         outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         return logits\n",
    "\n",
    "# # Define dataset class\n",
    "# class SentimentDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts[idx])\n",
    "#         label = self.labels[idx]\n",
    "#         encoding = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].squeeze(0),\n",
    "#             'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "#             'labels': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# # Preprocess data\n",
    "# df_post_tags['sentiment'] = df_post_tags['sentiment'].str.lower()\n",
    "# df_post_tags['label'] = df_post_tags['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "# df_post_tags = df_post_tags.dropna(subset=['label'])\n",
    "# df_post_tags['label'] = df_post_tags['label'].astype(int)\n",
    "\n",
    "# # Split off a fixed validation set (10% of data)\n",
    "# train_val_df, val_df = train_test_split(df_post_tags, test_size=0.1, random_state=42)\n",
    "# val_texts = val_df['review'].tolist()\n",
    "# val_labels = val_df['label'].tolist()\n",
    "# val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# # Use exactly 5000 samples for training\n",
    "# train_size = 5000\n",
    "# print(f\"\\nTraining with {train_size} samples...\")\n",
    "\n",
    "# # Subsample training data\n",
    "# train_df_sample = train_val_df.sample(n=min(train_size, len(train_val_df)), random_state=42)\n",
    "# train_texts = train_df_sample['review'].tolist()\n",
    "# train_labels = train_df_sample['label'].tolist()\n",
    "\n",
    "# # Create training dataset and loader\n",
    "# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# # Initialize model\n",
    "# model = BinarySentimentModel(base_model).to(device)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Store training history\n",
    "# history = {\n",
    "#     'train_loss': [],\n",
    "#     'val_loss': [],\n",
    "#     'val_acc': []\n",
    "# }\n",
    "\n",
    "# # Training loop with validation at each epoch\n",
    "# print(\"Starting training...\")\n",
    "# start_time = time.time()\n",
    "# num_epochs = 3\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_train_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(input_ids, attention_mask=attention_mask)\n",
    "#         loss = loss_fn(logits, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_train_loss += loss.item()\n",
    "    \n",
    "#     avg_train_loss = total_train_loss / len(train_loader)\n",
    "#     history['train_loss'].append(avg_train_loss)\n",
    "    \n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device)\n",
    "#             logits = model(input_ids, attention_mask=attention_mask)\n",
    "#             loss = loss_fn(logits, labels)\n",
    "#             val_loss += loss.item()\n",
    "#             preds = torch.argmax(logits, dim=-1)\n",
    "#             correct += (preds == labels).sum().item()\n",
    "#             total += labels.size(0)\n",
    "    \n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     accuracy = correct / total\n",
    "    \n",
    "#     # Store results\n",
    "#     history['val_loss'].append(avg_val_loss)\n",
    "#     history['val_acc'].append(accuracy)\n",
    "    \n",
    "#     print(f\"Epoch {epoch + 1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# training_time = time.time() - start_time\n",
    "# print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# # Save the model\n",
    "# torch.save(model.state_dict(), \"sentiment_model_5000_samples.pt\")\n",
    "# print(\"Model saved as 'sentiment_model_5000_samples.pt'\")\n",
    "\n",
    "# # Plot training results\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# # Plot Training and Validation Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(range(1, num_epochs + 1), history['train_loss'], marker='o', label=\"Training Loss\")\n",
    "# plt.plot(range(1, num_epochs + 1), history['val_loss'], marker='o', label=\"Validation Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Plot Validation Accuracy\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(range(1, num_epochs + 1), history['val_acc'], marker='o', color='green')\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Validation Accuracy\")\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"training_results.png\")\n",
    "# plt.show()\n",
    "\n",
    "# # ========================\n",
    "# # Evaluate on all 50k samples\n",
    "# # ========================\n",
    "# print(\"\\nEvaluating model on all 50k samples...\")\n",
    "# eval_start_time = time.time()\n",
    "\n",
    "# # Assume X contains all 50k text samples and y contains the corresponding labels\n",
    "# # Create a dataset for the full 50k samples\n",
    "# full_dataset = SentimentDataset(X, y, tokenizer)\n",
    "# batch_size = 32  # Adjust based on your GPU memory\n",
    "# full_loader = DataLoader(full_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Evaluate on the full dataset\n",
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_probs = []  # Store probabilities for ROC AUC calculation\n",
    "# all_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in full_loader:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['labels'].to(device)\n",
    "        \n",
    "#         logits = model(input_ids, attention_mask=attention_mask)\n",
    "#         probs = torch.softmax(logits, dim=1)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "#         all_preds.extend(preds.cpu().numpy())\n",
    "#         all_probs.extend(probs[:, 1].cpu().numpy())  # Probability for positive class\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# eval_time = time.time() - eval_start_time\n",
    "# print(f\"Evaluation completed in {eval_time:.2f} seconds\")\n",
    "\n",
    "# # Convert predictions and probabilities to numpy arrays\n",
    "# all_preds = np.array(all_preds)\n",
    "# all_probs = np.array(all_probs)\n",
    "# all_labels = np.array(all_labels)\n",
    "\n",
    "# # Calculate metrics\n",
    "# accuracy = accuracy_score(all_labels, all_preds)\n",
    "# print(f\"\\nAccuracy on all 50k samples: {accuracy:.4f}\")\n",
    "\n",
    "# # Calculate AUC-ROC \n",
    "# # Note: For binary classification, we use the probability of the positive class\n",
    "# auc_roc = roc_auc_score(all_labels, all_probs)\n",
    "# print(f\"AUC-ROC on all 50k samples: {auc_roc:.4f}\")\n",
    "\n",
    "# # Get the original class labels using the label encoder\n",
    "# pred_classes = le.inverse_transform(all_preds)\n",
    "# true_classes = le.inverse_transform(all_labels)\n",
    "\n",
    "# # Print classification report\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(true_classes, pred_classes))\n",
    "\n",
    "# # Create confusion matrix\n",
    "# cm = confusion_matrix(true_classes, pred_classes)\n",
    "# class_names = le.classes_\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.savefig(\"confusion_matrix.png\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot ROC curve\n",
    "# fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_roc:.4f})')\n",
    "# plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid(True)\n",
    "# plt.savefig(\"roc_curve.png\")\n",
    "# plt.show()\n",
    "\n",
    "# # Per-class metrics for multiclass classification (if applicable)\n",
    "# if len(class_names) > 2:\n",
    "#     # Calculate per-class AUC-ROC using one-vs-rest approach\n",
    "#     from sklearn.preprocessing import label_binarize\n",
    "#     from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "#     # Binarize the labels for multi-class ROC AUC\n",
    "#     y_bin = label_binarize(all_labels, classes=range(len(class_names)))\n",
    "    \n",
    "#     # Get model predictions with probabilities for each class\n",
    "#     model.eval()\n",
    "#     all_class_probs = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in full_loader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "#             logits = model(input_ids, attention_mask=attention_mask)\n",
    "#             probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "#             all_class_probs.append(probs)\n",
    "    \n",
    "#     all_class_probs = np.vstack(all_class_probs)\n",
    "    \n",
    "#     # Calculate AUC for each class\n",
    "#     roc_auc = {}\n",
    "#     for i in range(len(class_names)):\n",
    "#         roc_auc[class_names[i]] = roc_auc_score(y_bin[:, i], all_class_probs[:, i])\n",
    "    \n",
    "#     print(\"\\nAUC-ROC per class:\")\n",
    "#     for cls, auc in roc_auc.items():\n",
    "#         print(f\"{cls}: {auc:.4f}\")\n",
    "\n",
    "# # Display a few sample predictions\n",
    "# print(\"\\nSample Predictions:\")\n",
    "# sample_indices = np.random.choice(len(X), min(10, len(X)), replace=False)\n",
    "# for idx in sample_indices:\n",
    "#     text = X[idx]\n",
    "#     true_label = le.inverse_transform([all_labels[idx]])[0]\n",
    "#     pred_label = le.inverse_transform([all_preds[idx]])[0]\n",
    "#     prob = all_probs[idx]\n",
    "    \n",
    "#     print(f\"Text: '{text[:100]}...'\")\n",
    "#     print(f\"True label: {true_label}\")\n",
    "#     print(f\"Predicted label: {pred_label} (confidence: {prob:.4f})\")\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ea20e5bf6fce35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:09.622561Z",
     "start_time": "2025-03-17T15:03:09.611256Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder = LabelEncoder()\n",
    "# y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd3fa113df20f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:09.641139Z",
     "start_time": "2025-03-17T15:03:09.624567Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce09f4faf46c25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:19.827178Z",
     "start_time": "2025-03-17T15:03:09.642107Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Applying BoW\n",
    "# cv = CountVectorizer()\n",
    "# X_train_bow = cv.fit_transform(X_train['review'])\n",
    "# X_test_bow = cv.transform(X_test['review'])\n",
    "\n",
    "# X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec19eb7095bb88c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:19.831493Z",
     "start_time": "2025-03-17T15:03:19.828208Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# rf.fit(X_train_bow,y_train)\n",
    "# y_pred = rf.predict(X_test_bow)\n",
    "# accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cb2111860bbf86e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:03:19.839493Z",
     "start_time": "2025-03-17T15:03:19.832493Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71769cb6581cc87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:10:52.533061Z",
     "start_time": "2025-03-17T15:03:19.841494Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 1000, step=50),\n",
    "#         \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "#         \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True),\n",
    "#         \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True),\n",
    "#         \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "#         \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "#         \"objective\": \"binary:logistic\",\n",
    "#         \"eval_metric\": \"auc\",\n",
    "#         \"verbosity\": 0,\n",
    "#         \"tree_method\": \"hist\",\n",
    "#         \"device\": \"cuda\"\n",
    "#     }\n",
    "\n",
    "#     cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     aucs = []\n",
    "\n",
    "#     for train_idx, val_idx in cv.split(X_train_bow, y_train):\n",
    "#         X_tr, X_val = X_train_bow[train_idx], X_train_bow[val_idx]\n",
    "#         y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "#         dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "#         dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "#         model = xgb.train(\n",
    "#             params=params,\n",
    "#             dtrain=dtrain,\n",
    "#             evals=[(dvalid, \"eval\")],\n",
    "#             early_stopping_rounds=30,\n",
    "#             verbose_eval=False\n",
    "#         )\n",
    "\n",
    "#         preds = model.predict(dvalid, iteration_range=(0, model.best_iteration))\n",
    "#         auc = roc_auc_score(y_val, preds)\n",
    "#         aucs.append(auc)\n",
    "\n",
    "#     return np.mean(aucs)\n",
    "\n",
    "\n",
    "# # Run Optuna optimization\n",
    "# pruner = optuna.pruners.HyperbandPruner()\n",
    "# study = optuna.create_study(direction=\"maximize\",pruner=pruner)\n",
    "\n",
    "# # Define baseline trial as a fixed parameter suggestion\n",
    "# baseline_params = {\n",
    "#     'n_estimators': 550,\n",
    "#     'eta': 0.29983309207957676,\n",
    "#     'max_depth': 19,\n",
    "#     'subsample': 0.9888438323886279,\n",
    "#     'colsample_bytree': 0.6889387283870231,\n",
    "#     'lambda': 1.0481576423947685,\n",
    "#     'alpha': 0.023164905855125376,\n",
    "#     'min_child_weight': 10,\n",
    "#     'gamma': 3.4009242038001064,\n",
    "# }\n",
    "\n",
    "# # Add the trial to the queue to run\n",
    "# study.enqueue_trial(baseline_params)\n",
    "\n",
    "# study.optimize(objective,timeout=3600)\n",
    "\n",
    "# # Best hyperparameters found\n",
    "# best_params = study.best_params\n",
    "# print(f\"\\nðŸ”¹ Best Hyperparameters:\\n{best_params}\")\n",
    "\n",
    "# # Train final model with best hyperparameters on GPU\n",
    "# best_params[\"tree_method\"] = \"gpu_hist\"\n",
    "# best_params[\"device\"] = \"cuda\"\n",
    "\n",
    "# dtrain_cv = xgb.DMatrix(X_train_bow, label=y_train)\n",
    "# final_model = xgb.train(\n",
    "#     params=best_params,\n",
    "#     dtrain=dtrain_cv,\n",
    "# )\n",
    "\n",
    "# # Evaluate on Hold-Out Validation Set\n",
    "# dvalid = xgb.DMatrix(X_test_bow, label=y_test)\n",
    "# test_preds = final_model.predict(dvalid)\n",
    "\n",
    "# # Convert probabilities to binary labels\n",
    "# pred_labels = (test_preds > 0.5).astype(int)\n",
    "\n",
    "# accuracy_score(y_test,pred_labels)\n",
    "\n",
    "\n",
    "# {'n_estimators': 300, 'eta': 0.29945643753119816, 'max_depth': 20, 'subsample': 0.8783578562355324, 'colsample_bytree': 0.7338100018725511, 'lambda': 0.03509555712821362, 'alpha': 0.0029994420277393804, 'min_child_weight': 10, 'gamma': 2.7368297453515065}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a9421a-66a3-454b-bca2-5f56506aba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate on Hold-Out Validation Set\n",
    "# dvalid = xgb.DMatrix(X_test_bow, label=y_test)\n",
    "# test_preds = final_model.predict(dvalid)\n",
    "\n",
    "\n",
    "# accuracy_score(y_test,pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e1e62-aa48-4a63-b62a-3b9c8d0f3682",
   "metadata": {},
   "source": [
    "# Finetuning on different amount of samples for performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9bc58c042135d9d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-23T14:38:34.247390Z"
    },
    "editable": true,
    "jupyter": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import copy\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the model name\n",
    "# model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Load the base model\n",
    "# base_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# # Check if a GPU is available and set the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Define a custom model with a new classification head\n",
    "# class BinarySentimentModel(nn.Module):\n",
    "#     def __init__(self, base_model, num_labels=2):\n",
    "#         super(BinarySentimentModel, self).__init__()\n",
    "#         self.base_model = base_model\n",
    "#         hidden_size = base_model.config.hidden_size\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask=None, **kwargs):\n",
    "#         outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         return logits\n",
    "\n",
    "# # Define dataset class\n",
    "# class SentimentDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts[idx])\n",
    "#         label = self.labels[idx]\n",
    "#         encoding = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].squeeze(0),\n",
    "#             'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "#             'labels': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "\n",
    "# # Preprocess data\n",
    "# df_post_tags['sentiment'] = df_post_tags['sentiment'].str.lower()\n",
    "# df_post_tags['label'] = df_post_tags['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "# df_post_tags = df_post_tags.dropna(subset=['label'])\n",
    "# df_post_tags['label'] = df_post_tags['label'].astype(int)\n",
    "\n",
    "# # Split off a fixed validation set (10% of 50k = 5k samples)\n",
    "# train_val_df, val_df = train_test_split(df_post_tags, test_size=0.1, random_state=42)\n",
    "# val_texts = val_df['review'].tolist()\n",
    "# val_labels = val_df['label'].tolist()\n",
    "# val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# # Define training sizes to test\n",
    "# train_sizes = [100, 250, 500, 1000, 2500, 5000, 10000, 25000]\n",
    "\n",
    "# # Store results (accuracy and loss per epoch for each size)\n",
    "# results = {size: {'val_loss': [], 'val_acc': []} for size in train_sizes}\n",
    "\n",
    "# # Training and evaluation loop for each size\n",
    "# for size in train_sizes:\n",
    "#     print(f\"\\nTraining with {size} samples...\")\n",
    "    \n",
    "#     # Subsample training data\n",
    "#     train_df_sample = train_val_df.sample(n=min(size, len(train_val_df)), random_state=42)\n",
    "#     train_texts = train_df_sample['review'].tolist()\n",
    "#     train_labels = train_df_sample['label'].tolist()\n",
    "    \n",
    "#     # Create training dataset and loader\n",
    "#     train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "#     # Reset model\n",
    "#     model = BinarySentimentModel(copy.deepcopy(base_model)).to(device)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "#     loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     # Training loop with validation at each epoch\n",
    "#     num_epochs = 3\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Training\n",
    "#         model.train()\n",
    "#         total_train_loss = 0\n",
    "#         for batch in train_loader:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['labels'].to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             logits = model(input_ids, attention_mask=attention_mask)\n",
    "#             loss = loss_fn(logits, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_train_loss += loss.item()\n",
    "        \n",
    "#         avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 labels = batch['labels'].to(device)\n",
    "#                 logits = model(input_ids, attention_mask=attention_mask)\n",
    "#                 loss = loss_fn(logits, labels)\n",
    "#                 val_loss += loss.item()\n",
    "#                 preds = torch.argmax(logits, dim=-1)\n",
    "#                 correct += (preds == labels).sum().item()\n",
    "#                 total += labels.size(0)\n",
    "        \n",
    "#         avg_val_loss = val_loss / len(val_loader)\n",
    "#         accuracy = correct / total\n",
    "        \n",
    "#         # Store results\n",
    "#         results[size]['val_loss'].append(avg_val_loss)\n",
    "#         results[size]['val_acc'].append(accuracy)\n",
    "        \n",
    "#         print(f\"Epoch {epoch + 1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # Print final results\n",
    "# print(\"\\nFinal Results:\")\n",
    "# for size in train_sizes:\n",
    "#     print(f\"Training Size: {size}\")\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f\"  Epoch {epoch + 1} - Val Loss: {results[size]['val_loss'][epoch]:.4f}, Val Accuracy: {results[size]['val_acc'][epoch]:.4f}\")\n",
    "\n",
    "# # Optional: Plot results\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot Validation Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# for size in train_sizes:\n",
    "#     plt.plot(range(1, num_epochs + 1), results[size]['val_loss'], marker='o', label=f\"Size {size}\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Validation Loss\")\n",
    "# plt.title(\"Validation Loss vs. Epoch\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Plot Validation Accuracy\n",
    "# plt.subplot(1, 2, 2)\n",
    "# for size in train_sizes:\n",
    "#     plt.plot(range(1, num_epochs + 1), results[size]['val_acc'], marker='o', label=f\"Size {size}\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.title(\"Validation Accuracy vs. Epoch\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c9816-eda9-4a96-ba47-9b340d8a19e3",
   "metadata": {},
   "source": [
    "# Review length analysis in tokens (for bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9b80fef-6736-44a0-8dca-bdc0dee15b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import copy\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the model name\n",
    "# model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Load the base model\n",
    "# base_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# # Check if a GPU is available and set the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import pandas as pd\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import copy\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the model name\n",
    "# model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Load the base model\n",
    "# base_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# # Check if a GPU is available and set the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Preprocess data\n",
    "# df_post_tags['sentiment'] = df_post_tags['sentiment'].str.lower()\n",
    "# df_post_tags['label'] = df_post_tags['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "# df_post_tags = df_post_tags.dropna(subset=['label'])\n",
    "# df_post_tags['label'] = df_post_tags['label'].astype(int)\n",
    "\n",
    "# # Analyze review lengths in terms of tokens\n",
    "# def get_token_lengths(texts, tokenizer):\n",
    "#     token_lengths = []\n",
    "#     for text in texts:\n",
    "#         tokens = tokenizer(text, truncation=False, return_tensors=\"pt\", add_special_tokens=True)['input_ids'][0]\n",
    "#         token_lengths.append(len(tokens))\n",
    "#     return token_lengths\n",
    "\n",
    "# # Compute token lengths for the 'review' column\n",
    "# review_texts = df_post_tags['review'].tolist()\n",
    "# token_lengths = get_token_lengths(review_texts, tokenizer)\n",
    "\n",
    "# # Calculate max, median, and other stats\n",
    "# max_length = max(token_lengths)\n",
    "# median_length = int(np.median(token_lengths))\n",
    "# total_reviews = len(token_lengths)\n",
    "\n",
    "# print(f\"Review Length Analysis (in tokens):\")\n",
    "# print(f\"  Total Reviews: {total_reviews}\")\n",
    "# print(f\"  Maximum Token Length: {max_length}\")\n",
    "# print(f\"  Median Token Length: {median_length}\")\n",
    "\n",
    "# # Optional: Additional stats for deeper insight\n",
    "# percentile_90 = int(np.percentile(token_lengths, 90))\n",
    "# print(f\"  90th Percentile Token Length: {percentile_90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a08e0f-e7d6-4156-9dfb-112af66ca3cc",
   "metadata": {},
   "source": [
    "# Finetuning on 10k samples and saving the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1189661c-9da2-41ed-9bc8-21fa2d74a997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Selected 10000 samples for training from 44623 available.\n",
      "\n",
      "Saved 10000 training samples to train_10k_samples.csv\n",
      "Saved 4959 validation samples to validation_samples.csv\n",
      "Saved 34623 other remaining samples (not train or val) to other_remaining_samples.csv\n",
      "\n",
      "Starting training with 10000 samples...\n",
      "Epoch 1, Step 10/157 | Train Loss (Step): 0.5722 | Val Loss (Current): 0.5540 | Val Acc (Current): 0.7145\n",
      "Epoch 1, Step 20/157 | Train Loss (Step): 0.5521 | Val Loss (Current): 0.5335 | Val Acc (Current): 0.7201\n",
      "Epoch 1, Step 30/157 | Train Loss (Step): 0.5780 | Val Loss (Current): 0.5317 | Val Acc (Current): 0.7185\n",
      "Epoch 1, Step 40/157 | Train Loss (Step): 0.5276 | Val Loss (Current): 0.5171 | Val Acc (Current): 0.7358\n",
      "Epoch 1, Step 50/157 | Train Loss (Step): 0.6036 | Val Loss (Current): 0.5112 | Val Acc (Current): 0.7401\n",
      "Epoch 1, Step 60/157 | Train Loss (Step): 0.4977 | Val Loss (Current): 0.5078 | Val Acc (Current): 0.7407\n",
      "Epoch 1, Step 70/157 | Train Loss (Step): 0.4342 | Val Loss (Current): 0.5013 | Val Acc (Current): 0.7374\n",
      "Epoch 1, Step 80/157 | Train Loss (Step): 0.5455 | Val Loss (Current): 0.4960 | Val Acc (Current): 0.7516\n",
      "Epoch 1, Step 90/157 | Train Loss (Step): 0.5288 | Val Loss (Current): 0.5058 | Val Acc (Current): 0.7374\n",
      "Epoch 1, Step 100/157 | Train Loss (Step): 0.5746 | Val Loss (Current): 0.4974 | Val Acc (Current): 0.7481\n",
      "Epoch 1, Step 110/157 | Train Loss (Step): 0.5987 | Val Loss (Current): 0.4918 | Val Acc (Current): 0.7467\n",
      "Epoch 1, Step 120/157 | Train Loss (Step): 0.4984 | Val Loss (Current): 0.4887 | Val Acc (Current): 0.7502\n",
      "Epoch 1, Step 130/157 | Train Loss (Step): 0.5279 | Val Loss (Current): 0.4910 | Val Acc (Current): 0.7508\n",
      "Epoch 1, Step 140/157 | Train Loss (Step): 0.4920 | Val Loss (Current): 0.4801 | Val Acc (Current): 0.7568\n",
      "Epoch 1, Step 150/157 | Train Loss (Step): 0.4993 | Val Loss (Current): 0.4783 | Val Acc (Current): 0.7596\n",
      "\n",
      "Epoch 1 Training complete. Avg Train Loss: 0.5188\n",
      "Epoch 1 | Val Loss: 0.4858 | Val Accuracy: 0.7554\n",
      "Epoch 2, Step 10/157 | Train Loss (Step): 0.3300 | Val Loss (Current): 0.4952 | Val Acc (Current): 0.7479\n",
      "Epoch 2, Step 20/157 | Train Loss (Step): 0.4190 | Val Loss (Current): 0.5122 | Val Acc (Current): 0.7552\n",
      "Epoch 2, Step 30/157 | Train Loss (Step): 0.3387 | Val Loss (Current): 0.4856 | Val Acc (Current): 0.7538\n",
      "Epoch 2, Step 40/157 | Train Loss (Step): 0.4776 | Val Loss (Current): 0.4927 | Val Acc (Current): 0.7548\n",
      "Epoch 2, Step 50/157 | Train Loss (Step): 0.3377 | Val Loss (Current): 0.5003 | Val Acc (Current): 0.7536\n",
      "Epoch 2, Step 60/157 | Train Loss (Step): 0.5138 | Val Loss (Current): 0.4978 | Val Acc (Current): 0.7514\n",
      "Epoch 2, Step 70/157 | Train Loss (Step): 0.3679 | Val Loss (Current): 0.5091 | Val Acc (Current): 0.7532\n",
      "Epoch 2, Step 80/157 | Train Loss (Step): 0.4796 | Val Loss (Current): 0.5040 | Val Acc (Current): 0.7586\n",
      "Epoch 2, Step 90/157 | Train Loss (Step): 0.4149 | Val Loss (Current): 0.5020 | Val Acc (Current): 0.7574\n",
      "Epoch 2, Step 100/157 | Train Loss (Step): 0.3823 | Val Loss (Current): 0.4832 | Val Acc (Current): 0.7590\n",
      "Epoch 2, Step 110/157 | Train Loss (Step): 0.3299 | Val Loss (Current): 0.5229 | Val Acc (Current): 0.7477\n",
      "Epoch 2, Step 120/157 | Train Loss (Step): 0.4009 | Val Loss (Current): 0.5160 | Val Acc (Current): 0.7588\n",
      "Epoch 2, Step 130/157 | Train Loss (Step): 0.4116 | Val Loss (Current): 0.4726 | Val Acc (Current): 0.7610\n",
      "Epoch 2, Step 140/157 | Train Loss (Step): 0.4026 | Val Loss (Current): 0.4843 | Val Acc (Current): 0.7582\n",
      "Epoch 2, Step 150/157 | Train Loss (Step): 0.3107 | Val Loss (Current): 0.5043 | Val Acc (Current): 0.7625\n",
      "\n",
      "Epoch 2 Training complete. Avg Train Loss: 0.4108\n",
      "Epoch 2 | Val Loss: 0.4826 | Val Accuracy: 0.7610\n",
      "\n",
      "Fine-tuning finished.\n",
      "Model state dictionary saved successfully to fine_tuned_sentiment_model_10k_samples.pth\n",
      "\n",
      "--- Loading the saved model from fine_tuned_sentiment_model_10k_samples.pth ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:288: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Loaded model set to evaluation mode.\n",
      "\n",
      "Sample Inference using loaded model:\n",
      "Text: 'This is a great product!'\n",
      "Logits: tensor([[-2.0170,  2.0462]], device='cuda:0')\n",
      "Probabilities: tensor([[0.0169, 0.9831]], device='cuda:0')\n",
      "Predicted Class ID: 1\n",
      "Predicted Sentiment: positive\n",
      "CPU times: user 3min 14s, sys: 1min, total: 4min 14s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 2e-5\n",
    "MODEL_SAVE_PATH = \"fine_tuned_sentiment_model_10k_samples.pth\"\n",
    "TRAIN_SAMPLES_SAVE_PATH = \"train_10k_samples.csv\"      # Path to save training samples\n",
    "VAL_SAMPLES_SAVE_PATH = \"validation_samples.csv\"      # Path to save validation samples\n",
    "OTHER_SAMPLES_SAVE_PATH = \"test_set.csv\" # Path to save samples not in train or val\n",
    "\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Check if a GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define a custom model with a new classification head\n",
    "class BinarySentimentModel(nn.Module):\n",
    "    def __init__(self, base_model, num_labels=2):\n",
    "        super(BinarySentimentModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        hidden_size = base_model.config.hidden_size\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, **kwargs):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :] # Assuming [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Define dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=52): # Adjusted max_length\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# --- Data Loading and Preprocessing (Assuming df_post_tags is available) ---\n",
    "# If df_post_tags is not already loaded, load it here.\n",
    "# Example:\n",
    "# df_post_tags = pd.read_csv(\"your_data.csv\") # Replace with your data loading\n",
    "\n",
    "# Placeholder for df_post_tags. Replace with your actual data loading.\n",
    "# Ensure df_post_tags is loaded before this point.\n",
    "# For demonstration, creating a dummy DataFrame:\n",
    "if 'df_post_tags' not in locals():\n",
    "    print(\"Creating dummy df_post_tags. Replace with your actual data loading.\")\n",
    "    data = {'review': [f'This is a positive review {i}.' for i in range(25000)] + [f'This is a negative review {i}.' for i in range(25000)],\n",
    "            'sentiment': ['positive'] * 25000 + ['negative'] * 25000}\n",
    "    df_post_tags = pd.DataFrame(data)\n",
    "    df_post_tags = df_post_tags.sample(frac=1, random_state=42).reset_index(drop=True) # Shuffle\n",
    "\n",
    "\n",
    "# Add a unique identifier before any splitting/sampling\n",
    "df_post_tags['original_index'] = df_post_tags.index\n",
    "\n",
    "df_post_tags['sentiment'] = df_post_tags['sentiment'].str.lower()\n",
    "df_post_tags['label'] = df_post_tags['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df_post_tags = df_post_tags.dropna(subset=['label'])\n",
    "df_post_tags['label'] = df_post_tags['label'].astype(int)\n",
    "\n",
    "# --- Split Data ---\n",
    "# Split off a fixed validation set (e.g., 10% of the available data)\n",
    "train_val_df, val_df = train_test_split(df_post_tags, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define the training size\n",
    "TRAIN_SIZE = 10000\n",
    "\n",
    "# Subsample training data to exactly TRAIN_SIZE samples\n",
    "if len(train_val_df) > TRAIN_SIZE:\n",
    "    train_df_sample = train_val_df.sample(n=TRAIN_SIZE, random_state=42) # Do NOT reset index here yet\n",
    "    print(f\"Selected {len(train_df_sample)} samples for training from {len(train_val_df)} available.\")\n",
    "else:\n",
    "    train_df_sample = train_val_df # Use all available if less than TRAIN_SIZE\n",
    "    TRAIN_SIZE = len(train_df_sample) # Update TRAIN_SIZE to actual size\n",
    "    print(f\"Warning: Only {len(train_val_df)} samples available for training, using all ({TRAIN_SIZE}).\")\n",
    "\n",
    "\n",
    "# --- Identify and Save Data Splits ---\n",
    "\n",
    "# Get the 'original_index' of the samples used for training and validation\n",
    "used_train_indices = train_df_sample['original_index']\n",
    "used_val_indices = val_df['original_index'] # Get indices for the validation set\n",
    "\n",
    "# Filter original_df to get samples NOT in train or validation\n",
    "# Start with the original DataFrame and remove indices present in train_df_sample or val_df\n",
    "all_indices = df_post_tags['original_index']\n",
    "train_val_indices = pd.concat([used_train_indices, used_val_indices])\n",
    "other_samples_df = df_post_tags[~all_indices.isin(train_val_indices)]\n",
    "\n",
    "\n",
    "try:\n",
    "    # Save the training samples\n",
    "    train_df_sample_saved = train_df_sample.copy().drop(columns=['original_index']) # Drop original_index before saving if not needed\n",
    "    train_df_sample_saved.to_csv(TRAIN_SAMPLES_SAVE_PATH, index=False)\n",
    "    print(f\"\\nSaved {len(train_df_sample_saved)} training samples to {TRAIN_SAMPLES_SAVE_PATH}\")\n",
    "\n",
    "    # Save the validation samples\n",
    "    val_df_saved = val_df.copy().drop(columns=['original_index']) # Drop original_index before saving if not needed\n",
    "    val_df_saved.to_csv(VAL_SAMPLES_SAVE_PATH, index=False)\n",
    "    print(f\"Saved {len(val_df_saved)} validation samples to {VAL_SAMPLES_SAVE_PATH}\")\n",
    "\n",
    "    # Save the other remaining samples\n",
    "    other_samples_df_saved = other_samples_df.copy().drop(columns=['original_index']) # Drop original_index before saving if not needed\n",
    "    other_samples_df_saved.to_csv(OTHER_SAMPLES_SAVE_PATH, index=False)\n",
    "    print(f\"Saved {len(other_samples_df_saved)} other remaining samples (not train or val) to {OTHER_SAMPLES_SAVE_PATH}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saving data splits: {e}\")\n",
    "\n",
    "\n",
    "# --- Prepare Training Data (Now Reset Index for Dataset) ---\n",
    "# Reset index *after* identifying unused samples and saving train_df_sample\n",
    "# The saved train_df_sample retains the original_index if you need it later, but we use the reset version for the DataLoader\n",
    "train_df_sample = train_df_sample.reset_index(drop=True)\n",
    "\n",
    "train_texts = train_df_sample['review'].tolist()\n",
    "train_labels = train_df_sample['label'].tolist()\n",
    "\n",
    "# Create training dataset and loader\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "# Use the potentially adjusted TRAIN_SIZE in the print statement\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# --- Prepare Validation Data (using the saved val_df) ---\n",
    "# This part remains the same as val_df was already defined\n",
    "val_texts = val_df['review'].tolist()\n",
    "val_labels = val_df['label'].tolist()\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# --- Fine-tuning on TRAIN_SIZE Samples ---\n",
    "print(f\"\\nStarting training with {TRAIN_SIZE} samples...\")\n",
    "\n",
    "# Reset model (or initialize it for the first time in this run)\n",
    "# We keep the model initialization here before the training loop\n",
    "model = BinarySentimentModel(copy.deepcopy(base_model)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with validation at each epoch\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # --- Add Validation Calculation Every 10 Steps ---\n",
    "        if (step + 1) % 10 == 0: # Print progress and validate every 10 steps\n",
    "            current_train_loss = loss.item() # Loss for the current batch\n",
    "\n",
    "            # Perform Validation for this step's check\n",
    "            model.eval() # Set model to evaluation mode\n",
    "            step_val_loss = 0\n",
    "            step_correct = 0\n",
    "            step_total = 0\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    val_input_ids = val_batch['input_ids'].to(device)\n",
    "                    val_attention_mask = val_batch['attention_mask'].to(device)\n",
    "                    val_labels = val_batch['labels'].to(device)\n",
    "\n",
    "                    val_logits = model(val_input_ids, attention_mask=val_attention_mask)\n",
    "                    v_loss = loss_fn(val_logits, val_labels)\n",
    "                    step_val_loss += v_loss.item()\n",
    "\n",
    "                    val_preds = torch.argmax(val_logits, dim=-1)\n",
    "                    step_correct += (val_preds == val_labels).sum().item()\n",
    "                    step_total += val_labels.size(0)\n",
    "\n",
    "            # Calculate average validation metrics for this step's check\n",
    "            avg_step_val_loss = step_val_loss / len(val_loader)\n",
    "            step_accuracy = step_correct / step_total\n",
    "\n",
    "            # Print training loss for the current step PLUS validation metrics\n",
    "            print(f\"Epoch {epoch + 1}, Step {step + 1}/{len(train_loader)} | Train Loss (Step): {current_train_loss:.4f} | Val Loss (Current): {avg_step_val_loss:.4f} | Val Acc (Current): {step_accuracy:.4f}\")\n",
    "\n",
    "            model.train() # Set model back to training mode\n",
    "        # --- End of Validation Calculation Every 10 Steps ---\n",
    "\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch + 1} Training complete. Avg Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} | Val Loss: {avg_val_loss:.4f} | Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nFine-tuning finished.\")\n",
    "\n",
    "# --- Save the Fine-tuned Model ---\n",
    "# It's generally best practice to save the state_dict for custom models\n",
    "try:\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"Model state dictionary saved successfully to {MODEL_SAVE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n",
    "\n",
    "# --- Code to Load the Saved Model ---\n",
    "\n",
    "# To load the model, you need to first instantiate the model class\n",
    "# and then load the state dictionary.\n",
    "\n",
    "print(f\"\\n--- Loading the saved model from {MODEL_SAVE_PATH} ---\")\n",
    "\n",
    "# Ensure the model class and device are defined (they are in this script)\n",
    "# model_name = \"tabularisai/multilingual-sentiment-analysis\" # Already defined\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name) # Already defined\n",
    "# base_model_for_loading = AutoModel.from_pretrained(model_name) # Need a new instance or reuse\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Already defined\n",
    "\n",
    "# Instantiate the model\n",
    "loaded_model = BinarySentimentModel(AutoModel.from_pretrained(model_name)).to(device)\n",
    "\n",
    "# Load the state dictionary\n",
    "try:\n",
    "    # Check if the file exists before trying to load\n",
    "    if os.path.exists(MODEL_SAVE_PATH):\n",
    "        loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        loaded_model.eval()\n",
    "        print(\"Loaded model set to evaluation mode.\")\n",
    "\n",
    "        # You can now use 'loaded_model' for inference\n",
    "        # Example inference (using a sample text)\n",
    "        sample_text = \"This is a great product!\"\n",
    "        encoded_input = tokenizer(sample_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=52).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = loaded_model(encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'])\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "        sentiment_map = {1: 'positive', 0: 'negative'}\n",
    "        predicted_sentiment = sentiment_map.get(predicted_class_id, 'unknown')\n",
    "\n",
    "        print(f\"\\nSample Inference using loaded model:\")\n",
    "        print(f\"Text: '{sample_text}'\")\n",
    "        print(f\"Logits: {logits}\")\n",
    "        print(f\"Probabilities: {probabilities}\")\n",
    "        print(f\"Predicted Class ID: {predicted_class_id}\")\n",
    "        print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
    "    else:\n",
    "        print(f\"Error: Model file not found at {MODEL_SAVE_PATH}. Skipping model loading and inference example.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9015aefe-9813-4294-9eef-f46589e20b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running predictions on test_set.csv ---\n",
      "Loaded 34623 samples from test_set.csv\n",
      "Generating predictions...\n",
      "Prediction Step 100/541\n",
      "Prediction Step 200/541\n",
      "Prediction Step 300/541\n",
      "Prediction Step 400/541\n",
      "Prediction Step 500/541\n",
      "\n",
      "Performance Analysis on This Dataset:\n",
      "Total samples: 34623\n",
      "Correct predictions: 26526\n",
      "Incorrect predictions: 8097\n",
      "Accuracy on this set: 76.61%\n",
      "\n",
      "Predictions and performance saved to test_set_predictions.csv\n",
      "                                              review sentiment  label  \\\n",
      "0  One of the other reviewers has mentioned that ...  positive      1   \n",
      "1  I thought this was a wonderful way to spend ti...  positive      1   \n",
      "2  Basically there's a family where a little boy ...  negative      0   \n",
      "3  I sure would like to see a resurrection of a u...  positive      1   \n",
      "4  This show was an amazing, fresh & innovative i...  negative      0   \n",
      "\n",
      "   prob_negative  prob_positive  predicted_label  performance  \n",
      "0       0.668688       0.331312                0            0  \n",
      "1       0.029926       0.970074                1            1  \n",
      "2       0.957997       0.042003                0            1  \n",
      "3       0.494924       0.505076                1            1  \n",
      "4       0.038408       0.961592                1            0  \n"
     ]
    }
   ],
   "source": [
    "# --- Add imports if needed for this section ---\n",
    "# import pandas as pd # Already imported\n",
    "# import torch # Already imported\n",
    "# from torch.utils.data import DataLoader # Already imported\n",
    "# from torch.utils.data import Dataset # Already imported\n",
    "import numpy as np # Need numpy for concatenating probabilities\n",
    "\n",
    "\n",
    "# --- Code to Run Predictions on Other Remaining Samples ---\n",
    "\n",
    "OTHER_SAMPLES_LOAD_PATH = \"test_set.csv\" # Path to load the data\n",
    "PREDICTIONS_SAVE_PATH = \"test_set_predictions.csv\" # Path to save data with predictions\n",
    "\n",
    "print(f\"\\n--- Running predictions on {OTHER_SAMPLES_LOAD_PATH} ---\")\n",
    "\n",
    "# Check if the loaded_model is available and in evaluation mode\n",
    "if 'loaded_model' not in locals() or loaded_model is None:\n",
    "    print(\"Error: Model is not loaded. Please run the previous code block first.\")\n",
    "else:\n",
    "    try:\n",
    "        # Load the other remaining samples\n",
    "        if os.path.exists(OTHER_SAMPLES_LOAD_PATH):\n",
    "            other_df = pd.read_csv(OTHER_SAMPLES_LOAD_PATH)\n",
    "            print(f\"Loaded {len(other_df)} samples from {OTHER_SAMPLES_LOAD_PATH}\")\n",
    "\n",
    "            # Prepare data for prediction\n",
    "            prediction_texts = other_df['review'].tolist()\n",
    "            # Assuming 'label' column exists from previous saving steps:\n",
    "            prediction_labels = other_df['label'].tolist() # We need the true labels to calculate performance\n",
    "\n",
    "            prediction_dataset = SentimentDataset(prediction_texts, prediction_labels, tokenizer)\n",
    "            prediction_loader = DataLoader(prediction_dataset, batch_size=BATCH_SIZE, shuffle=False) # shuffle=False is important to keep order\n",
    "\n",
    "            # Run predictions\n",
    "            loaded_model.eval() # Ensure model is in evaluation mode\n",
    "            all_probs = []\n",
    "\n",
    "            print(\"Generating predictions...\")\n",
    "            with torch.no_grad():\n",
    "                for step, batch in enumerate(prediction_loader):\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    # Labels are not needed for inference itself, but Dataset returns them\n",
    "\n",
    "                    logits = loaded_model(input_ids, attention_mask=attention_mask)\n",
    "                    probs = torch.softmax(logits, dim=1) # Get probabilities\n",
    "\n",
    "                    all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "                    if (step + 1) % 100 == 0:\n",
    "                         print(f\"Prediction Step {step + 1}/{len(prediction_loader)}\")\n",
    "\n",
    "\n",
    "            # Concatenate all probabilities\n",
    "            all_probs = np.concatenate(all_probs, axis=0)\n",
    "\n",
    "            # Add probabilities to the DataFrame\n",
    "            other_df['prob_negative'] = all_probs[:, 0] # Probability for class 0\n",
    "            other_df['prob_positive'] = all_probs[:, 1] # Probability for class 1\n",
    "\n",
    "            # Add predicted class (0 or 1)\n",
    "            other_df['predicted_label'] = np.argmax(all_probs, axis=1)\n",
    "\n",
    "            # --- Add Performance Calculation ---\n",
    "            # Compare predicted label with the true label\n",
    "            other_df['performance'] = (other_df['predicted_label'] == other_df['label']).astype(int) # 1 if correct, 0 if wrong\n",
    "\n",
    "            # Calculate the percentage correct\n",
    "            percentage_correct = other_df['performance'].mean() * 100\n",
    "\n",
    "            print(f\"\\nPerformance Analysis on This Dataset:\")\n",
    "            print(f\"Total samples: {len(other_df)}\")\n",
    "            print(f\"Correct predictions: {other_df['performance'].sum()}\")\n",
    "            print(f\"Incorrect predictions: {len(other_df) - other_df['performance'].sum()}\")\n",
    "            print(f\"Accuracy on this set: {percentage_correct:.2f}%\")\n",
    "            # --- End of Performance Calculation ---\n",
    "\n",
    "\n",
    "            # Save the DataFrame with predictions and performance\n",
    "            other_df.to_csv(PREDICTIONS_SAVE_PATH, index=False)\n",
    "\n",
    "            print(f\"\\nPredictions and performance saved to {PREDICTIONS_SAVE_PATH}\")\n",
    "            print(other_df.head()) # Print the first few rows of the result\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: Data file not found at {OTHER_SAMPLES_LOAD_PATH}. Skipping prediction.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8c4d1-b667-4808-9368-ae2407407125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
